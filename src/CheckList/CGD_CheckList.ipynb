{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install checklist\n"
      ],
      "metadata": {
        "id": "NFQc61buWZRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLY7InudM1-4"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import checklist\n",
        "import spacy\n",
        "import itertools\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import checklist.editor\n",
        "import checklist.text_generation\n",
        "from checklist.test_types import MFT, INV, DIR\n",
        "from checklist.expect import Expect\n",
        "\n",
        "from checklist.test_suite import TestSuite\n",
        "from checklist.perturb import Perturb\n",
        "\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "#model\n",
        "model_name = \"Constien/xmlRoberta_all_lang\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# sentiment analysis is a general name in Huggingface to load the pipeline for text classification tasks.\n",
        "# set device=-1 if you don't have a gpu\n",
        "pipe = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, framework=\"pt\", device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJOOGNwBM1-8"
      },
      "outputs": [],
      "source": [
        "editor = checklist.editor.Editor()\n",
        "editor.tg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite = TestSuite()"
      ],
      "metadata": {
        "id": "mbyhaQuK7v0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zwj9M2SaM1--"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOYbXBPn7ov9",
        "outputId": "f856b806-9b12-479d-e867-05c7eccf664f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset\n",
        "engset=pd.read_csv('/content/drive/MyDrive/IM/VTPAN_csv/VTPAN-test.csv')\n"
      ],
      "metadata": {
        "id": "0Ptolg5R7ozX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predatory examples\n",
        "pred_set=engset.loc[engset['label'] == 'predator']"
      ],
      "metadata": {
        "id": "CZ1aBli57kqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#non predatory examples\n",
        "nopred_set=engset.loc[engset['label'] == 'non-predator']"
      ],
      "metadata": {
        "id": "Re04thoma6dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_set['segment_tur'] = pred_set['segment'].str[:1500]"
      ],
      "metadata": {
        "id": "2yG0E9xyTgMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.set_option('display.max_colwidth', None)\n",
        "pred_set['segment_tur'].str.len().max()"
      ],
      "metadata": {
        "id": "qQT6RGYrfW_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nopred_set['segment_tur'] = nopred_set['segment'].str[:1500]"
      ],
      "metadata": {
        "id": "UZzIPlv0gwKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHU-JiG5M1-_"
      },
      "outputs": [],
      "source": [
        "sentences = pred_set['segment_tur']\n",
        "\n",
        "pdata = list(nlp.pipe(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_nopred = nopred_set['segment_tur']\n",
        "\n",
        "pdata_nopred = list(nlp.pipe(sentences_nopred))"
      ],
      "metadata": {
        "id": "yW4VCq7Bg_oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=list(sentences)\n",
        "#sentences_nopred=list(sentences_nopred)"
      ],
      "metadata": {
        "id": "4K13eKQPDbtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3j76LmYM1-_"
      },
      "source": [
        "**Capability: neumeric reasoning**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def change_age(x, *args, **kwargs):\n",
        "    # Returns empty or a list of strings with age changed\n",
        "    age =  ['25', '30', '35', '40', '45', '50']\n",
        "    age_replace= ['12', '13', '14','15', '16', '17']\n",
        "\n",
        "    ret = []\n",
        "    for p in age:\n",
        "        if re.search(r'\\b%s\\b' % p, x):\n",
        "            ret.extend([re.sub(r'\\b%s\\b' % p, p2, x) for p2 in age_replace if p != p2])\n",
        "    return ret\n"
      ],
      "metadata": {
        "id": "axdud5Wh6SKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = Perturb.perturb(sentences_nopred, change_age)\n",
        "#ret.sentences"
      ],
      "metadata": {
        "id": "23kEpXGl7cXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = MFT(ret.data, labels=1)\n",
        "suite.add(test,  'Age', 'Neumeric Reasoning', overwrite=True )"
      ],
      "metadata": {
        "id": "_Ddkf7YWgBLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_conf(data):\n",
        "    raw_preds = pipe(data)\n",
        "    preds = np.array([ int(p[\"label\"][-1]) for p in raw_preds])\n",
        "    pp = np.array([[p[\"score\"], 1-p[\"score\"]] if int(p[\"label\"][-1]) == 'predator' else [1-p[\"score\"], p[\"score\"]] for p in raw_preds])\n",
        "    return preds, pp"
      ],
      "metadata": {
        "id": "Z9gA-FTegsMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suite.summary()"
      ],
      "metadata": {
        "id": "SGnOpSdway4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suite.run(pred_and_conf, overwrite=True)"
      ],
      "metadata": {
        "id": "qlcYgS06gjSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suite.summary()  # label 1, complete data 1 and 0"
      ],
      "metadata": {
        "id": "AmbqfPbmGj0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Capability: vocabulary**"
      ],
      "metadata": {
        "id": "khm8x6AGjSYO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5El74jW_M1_B"
      },
      "outputs": [],
      "source": [
        "#parent nouns\n",
        "#parent_noun = ['dad', 'mom', 'aunt', 'grandma', 'uncle', 'grandfather', 'my grandmother', 'grandpa', 'my older sister', 'brother']\n",
        "#editor.add_lexicon('parent_noun', parent_noun, overwrite=True)\n",
        "\n",
        "names = ['my sweety', 'baby', 'babyy', 'babbby', 'little girl', 'sexy', 'darling','cutey', 'pussycat', 'angel', 'kiddo', 'kid', 'my girl', 'gorgeous']\n",
        "editor.add_lexicon('names', names, overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d18k29BhM1_C"
      },
      "outputs": [],
      "source": [
        "# positive adjectives\n",
        "pos_adj = ['sexy','mesexy', 'great', 'allsome', 'amazing', 'extraordinary', 'beautiful', 'fantastic', 'nice', 'attractive', 'girly', 'awesome', 'perfect', 'fun', 'cool', 'adorable', 'smart', 'exciting', 'sweet', 'wonderful']\n",
        "editor.add_lexicon('pos_adj', pos_adj, overwrite=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#negative_adj = ['lame', 'shitty', 'not worthy', 'unattractive', 'not sexy', 'not beautiful', 'not nice']\n",
        "#editor.add_lexicon('neutral_adj', pos_adj, overwrite=True)\n"
      ],
      "metadata": {
        "id": "FnMdBbcxJVIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsa95UW9M1_C",
        "outputId": "e6fc352d-5abb-497d-90fa-c3b799c6481d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to, with, for, tell, see, call, of, told, update, from, t, thank, write, tel, at, visit, -, show, called, hug, on, post, miss, w, help, hear, di, warn, near, without, leave, hold, msg, get, th, message, around, make, meet, bother\n"
          ]
        }
      ],
      "source": [
        "# get model suggestion for possible neutral verbs\n",
        "#print(', '.join(editor.suggest('I cant {a:mask} you today, {parent_noun} is home tonight.')[:40]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o34Z0enGM1_E"
      },
      "outputs": [],
      "source": [
        "#pos_verb_present = ['like', 'enjoy', 'appreciate', 'love', 'admire', 'value']\n",
        "#neutral_verb_present = ['call', 'see', 'visit', 'write', 'be near', 'come over', 'invite', 'msg', 'message', 'text', 'go online', 'log in', 'hug', 'touch', 'kiss', 'lick', 'smell']\n",
        "#pos_verb_past = ['liked', 'enjoyed', 'appreciated', 'loved', 'admired', 'valued', 'welcomed']\n",
        "#neutral_verb_past = ['called', 'saw', 'visited', 'wrote', 'was near', 'came over', 'invited', 'messaged', 'texted', 'came online', 'logged in', 'hugged', 'touched', 'kissed', 'licked', 'smelled']\n",
        "\n",
        "#editor.add_lexicon('pos_verb_present', pos_verb_present, overwrite=True)\n",
        "#editor.add_lexicon('neutral_verb_present', neutral_verb_present, overwrite=True)\n",
        "#editor.add_lexicon('pos_verb_past', pos_verb_past, overwrite=True)\n",
        "#editor.add_lexicon('neutral_verb_past', neutral_verb_past, overwrite=True)\n",
        "#editor.add_lexicon('pos_verb', pos_verb_present+ pos_verb_past, overwrite=True)\n",
        "#editor.add_lexicon('neutral_verb', neutral_verb_present + neutral_verb_past, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIXuBtYrM1_E"
      },
      "source": [
        "Individual words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_conf(data):\n",
        "    raw_preds = pipe(data)\n",
        "    preds = np.array([ int(p[\"label\"][-1]) for p in raw_preds])\n",
        "    pp = np.array([[p[\"score\"], 1-p[\"score\"]] if int(p[\"label\"][-1]) == 'predator' else [1-p[\"score\"], p[\"score\"]] for p in raw_preds])\n",
        "    return preds, pp"
      ],
      "metadata": {
        "id": "9nPdCQaqvhSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_NiWords(x):\n",
        "    phrases = ['my sweety', 'baby', 'babyy', 'babbby', 'little girl', 'sexy', 'darling','cutie', 'angel', 'kiddo', 'kid', 'my girl', 'gorgeous']\n",
        "    return ['%s %s' % (x, p) for p in phrases]"
      ],
      "metadata": {
        "id": "JKy7zD5qogvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monotonic_increasing = Expect.monotonic(label=1, increasing=False, tolerance=0.1)\n"
      ],
      "metadata": {
        "id": "5DhPUzC4rz5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTz2ps5yM1_F"
      },
      "outputs": [],
      "source": [
        "t = Perturb.perturb(sentences, add_NiWords)\n",
        "test = DIR(**t, expect=monotonic_increasing)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.run(pred_and_conf)\n",
        "test.summary()"
      ],
      "metadata": {
        "id": "_Dzb2cdAs9Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMoCLvz1M1_N"
      },
      "source": [
        "Add phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH8w7zEqM1_V"
      },
      "outputs": [],
      "source": [
        "positive = editor.template('I {pos_verb_present} you.').data\n",
        "positive += editor.template('You are my {pos_adj}.').data\n",
        "positive += ['I would like to {neutral_verb_present} if your {parent_nount} not home.']\n",
        "def add_phrase_function(phrases):\n",
        "    def pert(d):\n",
        "        while d[-1].pos_ == 'PUNCT':\n",
        "            d = d[:-1]\n",
        "        d = d.text\n",
        "        ret = [d + '. ' + x for x in phrases]\n",
        "        idx = np.random.choice(len(ret), 10, replace=False)\n",
        "        ret = [ret[i] for i in idx]\n",
        "        return ret\n",
        "    return pert\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8hwtslyM1_W"
      },
      "outputs": [],
      "source": [
        "t = Perturb.perturb(pdata, add_phrase_function(positive), nsamples=500)\n",
        "test = MFT(t.data, labels=1)\n",
        "description = 'Add very predator laden words to the end of sentences, expect probability of negative to go up (tolerance=0.1)'\n",
        "suite.add(test, 'add positive phrases', 'Vocabulary', description, overwrite=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.run(pred_and_conf, overwrite=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx0DLYN4YHPE",
        "outputId": "151bb572-469d-473f-c6eb-52d88e502e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running add positive phrases\n",
            "Predicting 5500 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.summary()"
      ],
      "metadata": {
        "id": "e0fDx_ieYqyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbckZ1Q3M1_W"
      },
      "source": [
        "**Capability: robustness**\n",
        "\n",
        "adding irrelevant stuff before and after.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNSYSbdWM1_W"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "def random_string(n):\n",
        "    return ''.join(np.random.choice([x for x in string.ascii_letters + string.digits], n))\n",
        "def random_url(n=6):\n",
        "    return 'https://t.co/%s' % random_string(n)\n",
        "def random_handle(n=6):\n",
        "    return '@%s' % random_string(n)\n",
        "\n",
        "\n",
        "def add_irrelevant(sentence):\n",
        "    urls_and_handles = [random_url(n=6) for _ in range(5)] + [random_handle() for _ in range(5)]\n",
        "    irrelevant_before = ['@user '] + urls_and_handles\n",
        "    irrelevant_after = urls_and_handles\n",
        "    rets = ['%s %s' % (x, sentence) for x in irrelevant_before ]\n",
        "    rets += ['%s %s' % (sentence, x) for x in irrelevant_after]\n",
        "    return rets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z8WXElfM1_X"
      },
      "outputs": [],
      "source": [
        "t = Perturb.perturb(pdata, add_irrelevant, nsamples=500)\n",
        "test = INV(t.data)\n",
        "suite.add(test, 'add random urls and handles', 'Robustness', 'add randomly generated urls and handles to the start or end of sentence', overwrite=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MScpgTKM1_X"
      },
      "source": [
        "punctuation, contractions, typos\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnYOUCl8M1_X"
      },
      "outputs": [],
      "source": [
        "t = Perturb.perturb(pdata, Perturb.punctuation, nsamples=500)\n",
        "test = INV(t.data)\n",
        "suite.add(test, 'punctuation', 'Robustness', 'strip punctuation and / or add \".\"', overwrite=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4ixnk79M1_Y"
      },
      "outputs": [],
      "source": [
        "t = Perturb.perturb(sentences, Perturb.add_typos, nsamples=500, typos=1)\n",
        "test = INV(t.data)\n",
        "suite.add(test, 'typos', 'Robustness', 'Add one typo to input by swapping two adjacent characters', overwrite=True )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpwGX9ykM1_Y"
      },
      "outputs": [],
      "source": [
        "t = Perturb.perturb(sentences, Perturb.add_typos, nsamples=500, typos=2)\n",
        "test = INV(t.data)\n",
        "suite.add(test, '2 typos', 'Robustness', 'Add two typos to input by swapping two adjacent characters twice', overwrite=True )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quO6SaWUM1_Y"
      },
      "outputs": [],
      "source": [
        "t = Perturb.perturb(sentences, Perturb.contractions, nsamples=1000)\n",
        "test = INV(t.data)\n",
        "suite.add(test, 'contractions', 'Robustness', 'Contract or expand contractions, e.g. What is -> What\\'s', overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_conf(data):\n",
        "    raw_preds = pipe(data)\n",
        "    preds = np.array([ int(p[\"label\"][-1]) for p in raw_preds])\n",
        "    pp = np.array([[p[\"score\"], 1-p[\"score\"]] if int(p[\"label\"][-1]) == 'predator' else [1-p[\"score\"], p[\"score\"]] for p in raw_preds])\n",
        "    return preds, pp"
      ],
      "metadata": {
        "id": "_7pItjCVEC2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suite.run(pred_and_conf, overwrite=True)"
      ],
      "metadata": {
        "id": "BWDpE-PH3AvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suite.summary()"
      ],
      "metadata": {
        "id": "wRkPq9Ks3aaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#suite.visual_summary_table()"
      ],
      "metadata": {
        "id": "3ct5ZjwyVmBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE1kfcByM1_e"
      },
      "source": [
        "**Capability: negation**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's find some positive and negative adjectives\n",
        "', '.join(editor.suggest('This do not want to {a:mask} you.')[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MgFfQIrHBaWi",
        "outputId": "d4a44e2f-b393-4d49-bd83-2cda0be137da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hurt, to, with, upset, stop, on, provoke, of, for, offend, help, you, attack, abuse, end, insult, embarrass, up, exploit, about, affect, out, change, inconvenience, injure, bother, off, educate, harm, impact'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_conf(data):\n",
        "    raw_preds = pipe(data)\n",
        "    preds = np.array([ int(p[\"label\"][-1]) for p in raw_preds])\n",
        "    pp = np.array([[p[\"score\"], 1-p[\"score\"]] if int(p[\"label\"][-1]) == 'predator' else [1-p[\"score\"], p[\"score\"]] for p in raw_preds])\n",
        "    return preds, pp"
      ],
      "metadata": {
        "id": "urfSDuTrOxcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verb = ['meet', 'call', 'chat', 'talk', 'see', 'exploit']\n",
        "#ret = editor.template('I do not want to {verb} you.', verb=verb, labels=0, save=True, nsamples=300)"
      ],
      "metadata": {
        "id": "UaZe0rkmAvhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = Perturb.perturb(pdata, Perturb.add_negation)\n",
        "#ret.data"
      ],
      "metadata": {
        "id": "Krhgl3kWNzxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = INV(t.data, labels=1)\n",
        "suite.add(test, 'simple negations', 'Negation', 'Negating predator statements should result in non-predator predictions', overwrite=True )\n"
      ],
      "metadata": {
        "id": "K7UNhex7Nz1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suite.run(pred_and_conf)"
      ],
      "metadata": {
        "id": "_BTruPPa7B-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suite.summary()"
      ],
      "metadata": {
        "id": "9c0afliS7H6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqREouhGM1_l"
      },
      "source": [
        "**Capability: taxonomy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "editor.synonyms('I like young girls.', 'young')\n",
        "editor.synonyms('I prefer younger girls.', 'younger')\n",
        "\n",
        "synonyms = [('young', 'underage'), ('young', 'amature'), ('young', 'childish'), ('young', 'little'), ('young', 'teenage')]\n"
      ],
      "metadata": {
        "id": "_T1wjQnPFYhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = editor.template([(\n",
        "    'Hi, asl? 13 f from New York. You? kewl, Im Mike 40, Florida. I prefer talking to {x[1]} girls, I prefer {x[0]} girls, just like you sweety',\n",
        "    'I like very {x[0]} girls',\n",
        "    'I prefer {x[0]} girls',\n",
        "    ),\n",
        "    (\n",
        "    'Hi, asl? 13 f from New York. You? Im Mike 40, Florida. I like {x[1]} girls, wanna chat?',\n",
        "    'I like very {x[1]} girls',\n",
        "    'I prefer {x[1]} girls',\n",
        "    #'DO you prefer {x[1]} girls?',\n",
        "    )],\n",
        "    unroll=True,\n",
        "    x=synonyms,\n",
        "    remove_duplicates=True,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    nsamples=500,\n",
        "    overwrite=True)\n",
        "name = 'replace age describing adj'\n",
        "desc = ''\n",
        "test = MFT(**t, labels=1, name=name, capability = 'Taxonomy',\n",
        "          description=desc)\n",
        "suite.add(test, overwrite= True)"
      ],
      "metadata": {
        "id": "5f2nLEv0SI3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suite.run(pred_and_conf, overwrite=True)"
      ],
      "metadata": {
        "id": "sDphTWODSI9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suite.summary()"
      ],
      "metadata": {
        "id": "U1pgOhFIGQvQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "checklist",
      "language": "python",
      "name": "checklist"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}